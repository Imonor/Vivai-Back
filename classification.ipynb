{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#data scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split , KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         sentence intention\n",
      "0    Est ce que j'ai besoin d'arroser ma plante ?  arrosage\n",
      "1               Quand dois-je arroser ma plante ?  arrosage\n",
      "2                     Dois-je arroser ma plante ?  arrosage\n",
      "3             Comment puis-je arroser ma plante ?  arrosage\n",
      "4          Ma plante a besoin de beaucoup d'eau ?  arrosage\n",
      "..                                            ...       ...\n",
      "210                            je suis allergique  maladies\n",
      "211                          risque de maladies ?  maladies\n",
      "212                  comment protéger ma plante ?  maladies\n",
      "213                                   coccinelles  maladies\n",
      "214            dois je utiliser des coccinelles ?  maladies\n",
      "\n",
      "[215 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "data = pd.read_csv(\"TrainingSet1.csv\")\n",
    "\n",
    "print( data )\n",
    "\n",
    "#temporaire pour moins de données\n",
    "#data = data.head()\n",
    "\n",
    "intentions = data[\"intention\"].unique()\n",
    "data[\"intention\"] = data[\"intention\"].replace({\"arrosage\" : np.where( intentions == 'arrosage'),\n",
    "                                              \"soleil\": np.where( intentions == 'soleil'), \n",
    "                                              \"tailler\" : np.where( intentions == 'tailler'),\n",
    "                                              \"temperature\" : np.where( intentions == 'temperature'),\n",
    "                                              \"cadeaux\" : np.where( intentions == 'cadeaux'),\n",
    "                                              \"varietes\" : np.where( intentions == 'varietes'),\n",
    "                                              \"entretien\" : np.where( intentions == 'entretien'),\n",
    "                                               \"utilisation\" : np.where( intentions == 'utilisation'),\n",
    "                                               \"planter\" : np.where( intentions == 'planter'),\n",
    "                                               \"maladies\" : np.where( intentions == 'maladies')\n",
    "                                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(data[\"intention\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = data[\"sentence\"].tolist()\n",
    "j=0;\n",
    "\n",
    "#dictionnaire des mots connus\n",
    "words = list()\n",
    "allowed_pos = ['VERB', 'NOUN', 'PROPN', 'ADJ']\n",
    "\n",
    "# process sentences\n",
    "for i in data[\"sentence\"]:\n",
    "    # convert all letters to lower case\n",
    "    i = i.lower()\n",
    "    i = i.replace('-', ' ')\n",
    "    \n",
    "    regex = re.compile(\"plante([^r]|$)\")\n",
    "    i = regex.sub('', i)\n",
    "    \n",
    "    nlp_fr = spacy.load('fr_core_news_sm')\n",
    "    tokens = nlp_fr(i)\n",
    "\n",
    "    new_sentence = ''\n",
    "    for token in tokens:\n",
    "        if ( allowed_pos.count(token.pos_) > 0 ):\n",
    "                if (token.lemma_ != 't'): \n",
    "                    new_sentence += str(token.lemma_) + ' '\n",
    "                    words.append(str(token.lemma_))\n",
    "        \n",
    "    liste[j] = new_sentence;\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(liste).todense() #renvoie le bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compt_svm = 0\n",
    "\n",
    "for train_index, test_index in loo.split(X): \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for index in train_index:\n",
    "        X_train+=X[index].tolist()\n",
    "        y_train.append(y[index])\n",
    "    X_test = X[test_index].tolist()\n",
    "    y_test = y[int(test_index)]\n",
    "    \n",
    "    clf_svm = svm.SVC(kernel='linear')\n",
    "    clf_svm.fit(X_train, y_train)\n",
    "\n",
    "    if( clf_svm.predict(X_test) != 'nan' ):\n",
    "        if int(clf_svm.predict(X_test))==y_test:  # si prediction svm correcte\n",
    "            compt_svm += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision & Recall SVM : 0.7534883720930232\n"
     ]
    }
   ],
   "source": [
    "print(\"Précision & Recall SVM :\", compt_svm/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_svm.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(clf_svm, 'clf_svm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avant de les charger à nouveau\n",
    "clf_svm = load('clf_svm.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrosage\n"
     ]
    }
   ],
   "source": [
    "# Test with a simple sentence\n",
    "s = \"Dois je donner de l'eau à ma plante\"\n",
    "\n",
    "# Pre-processing\n",
    "s = s.lower()\n",
    "\n",
    "regex = re.compile(\"plante([^r]|$)\")\n",
    "s = regex.sub('', s)\n",
    "\n",
    "nlp_fr = spacy.load('fr_core_news_sm')\n",
    "tokens = nlp_fr(s)\n",
    "\n",
    "words = list()\n",
    "                \n",
    "# Lemmatize\n",
    "for token in tokens:\n",
    "    if ( allowed_pos.count(token.pos_) > 0 ):\n",
    "        if (token.lemma_ != 't'): \n",
    "            words.append(str(token.lemma_))\n",
    "\n",
    "           \n",
    "j = 0;\n",
    "vector = vectorizer.get_feature_names()\n",
    "\n",
    "# Create vector\n",
    "for word in vector:\n",
    "    vector[j] = words.count(word);           \n",
    "    j += 1\n",
    "\n",
    "\n",
    "\n",
    "p = clf_svm.predict([vector])\n",
    "print(intentions[ int(p[0]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
