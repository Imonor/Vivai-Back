{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#data scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split , KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             sentence    intention\n",
      "0        Est ce que j'ai besoin d'arroser ma plante ?     arrosage\n",
      "1                   Quand dois-je arroser ma plante ?     arrosage\n",
      "2                         Dois-je arroser ma plante ?     arrosage\n",
      "3                 Comment puis-je arroser ma plante ?     arrosage\n",
      "4              Ma plante a besoin de beaucoup d'eau ?     arrosage\n",
      "..                                                ...          ...\n",
      "84                     dois je réchauffer ma plante ?  temperature\n",
      "85                                refroidir la plante  temperature\n",
      "86              comment puis-je refroidir ma plante ?  temperature\n",
      "87  garder sa plante entre combien et combien de d...  temperature\n",
      "88      à combien de degrés dois-je garder ma plante?  temperature\n",
      "\n",
      "[89 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "data = pd.read_csv(\"TrainingSet1.csv\")\n",
    "\n",
    "print( data )\n",
    "\n",
    "#temporaire pour moins de données\n",
    "#data = data.head()\n",
    "\n",
    "intentions = data[\"intention\"].unique()\n",
    "data[\"intention\"] = data[\"intention\"].replace({\"arrosage\" : np.where( intentions == 'arrosage'),\n",
    "                                              \"soleil\": np.where( intentions == 'soleil'), \n",
    "                                              \"tailler\" : np.where( intentions == 'tailler'),\n",
    "                                              \"temperature\" : np.where( intentions == 'temperature')\n",
    "                                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(data[\"intention\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = data[\"sentence\"].tolist()\n",
    "j=0;\n",
    "\n",
    "#dictionnaire des mots connus\n",
    "words = list()\n",
    "allowed_pos = ['VERB', 'NOUN', 'PROPN', 'ADJ']\n",
    "\n",
    "# process sentences\n",
    "for i in data[\"sentence\"]:\n",
    "    # convert all letters to lower case\n",
    "    i = i.lower()\n",
    "    i = i.replace('-', ' ')\n",
    "\n",
    "    nlp_fr = spacy.load('fr_core_news_sm')\n",
    "    tokens = nlp_fr(i)\n",
    "\n",
    "    new_sentence = ''\n",
    "    for token in tokens:\n",
    "        if ( allowed_pos.count(token.pos_) > 0 ):\n",
    "            if (token.lemma_ != 'plante' and token.lemma_ != 't'): \n",
    "                new_sentence += str(token.lemma_) + ' '\n",
    "                words.append(str(token.lemma_))\n",
    "        \n",
    "    liste[j] = new_sentence;\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(liste).todense() #renvoie le bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compt_naive_bayes = 0\n",
    "compt_svm = 0\n",
    "\n",
    "for train_index, test_index in loo.split(X):  #les differents jeux de données\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for index in train_index:\n",
    "        X_train+=X[index].tolist()\n",
    "        y_train.append(y[index])\n",
    "    X_test = X[test_index].tolist()\n",
    "    y_test = y[int(test_index)]\n",
    "    \n",
    "    clf_svm = svm.SVC(kernel='linear')\n",
    "    clf_bayes = MultinomialNB(alpha=0.01)\n",
    "    clf_svm.fit(X_train, y_train)\n",
    "    clf_bayes.fit(X_train, y_train)\n",
    "    \n",
    "    if int(clf_bayes.predict(X_test))==y_test:  # si prediction naive bayes correcte\n",
    "        compt_naive_bayes += 1 \n",
    "        \n",
    "    if int(clf_svm.predict(X_test))==y_test:  # si prediction svm correcte\n",
    "        compt_svm += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision & Recall Naive Bayes : 0.7415730337078652\n",
      "Précision & Recall SVM : 0.8202247191011236\n"
     ]
    }
   ],
   "source": [
    "print(\"Précision & Recall Naive Bayes :\", compt_naive_bayes/len(X)) \n",
    "print(\"Précision & Recall SVM :\", compt_svm/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_svm.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportons les deux modèles...\n",
    "\n",
    "from joblib import dump, load\n",
    "dump(clf_bayes, 'clf_bayes.joblib') \n",
    "dump(clf_svm, 'clf_svm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avant de les charger à nouveau\n",
    "clf_bayes = load('clf_bayes.joblib') \n",
    "clf_svm = load('clf_svm.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soleil']\n"
     ]
    }
   ],
   "source": [
    "# Test with a simple sentence\n",
    "s = \"avoir besoin soleil ?\"\n",
    "\n",
    "# Pre-processing\n",
    "s = s.lower()\n",
    "\n",
    "nlp_fr = spacy.load('fr_core_news_sm')\n",
    "tokens = nlp_fr(s)\n",
    "\n",
    "words = list()\n",
    "                \n",
    "# Lemmatize\n",
    "for token in tokens:\n",
    "    if ( allowed_pos.count(token.pos_) > 0 ):\n",
    "        if (token.lemma_ != 'plante' and token.lemma_ != 't'): \n",
    "            words.append(str(token.lemma_))\n",
    "\n",
    "           \n",
    "j = 0;\n",
    "vector = vectorizer.get_feature_names()\n",
    "\n",
    "# Create vector\n",
    "for word in vector:\n",
    "    vector[j] = words.count(word);           \n",
    "    j += 1\n",
    "\n",
    "\n",
    "\n",
    "p = clf_svm.predict([vector])\n",
    "print(intentions[p])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
